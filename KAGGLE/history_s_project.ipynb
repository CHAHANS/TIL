{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "items = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n",
    "submission_sample = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\n",
    "cats = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n",
    "train = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n",
    "shops = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카테고리 코드정리\n",
    "#1. 문자열 분리\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "#2. [0]인 값만 사용, [1]의 unique()가 너무 많고, 최대 중복이 4여서 버림\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "\n",
    "#3. 카테고리 병합(PC와 모바일 게임도 게임으로 재분류)\n",
    "cats.loc[cats['type']=='Игры PC','type'] = 'Игры'\n",
    "cats.loc[cats['type']=='Игры MAC','type'] = 'Игры'\n",
    "cats.loc[cats['type']=='Игры Android''type'] = 'Игры'\n",
    "\n",
    "#4. 중복이 4보다 적은 값은 orters로 분류 -> label or onehot을 위해 최소화\n",
    "cat_types =[]\n",
    "for i in cats['type'].unique():\n",
    "    if len(cats[cats['type'] == i]) >= 4:\n",
    "        cat_types.append(i)\n",
    "cats['type'] = cats['type'].apply(lambda x: x if (x in cat_types) else \"orters\")\n",
    "#5. 라벨인코더 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "hot_model = LabelEncoder()\n",
    "cats['type_1'] = hot_model.fit_transform(cats['type'])\n",
    "\n",
    "#6. 병합할 데이터 셋 \n",
    "#병합시 Key(on) = item_category_id\n",
    "cats_final = pd.DataFrame({'item_category_id':cats['item_category_id'],'type':cats['type_1']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item name은 cats의 type과 성질이 유사하여 삭제\n",
    "items = pd.merge(items,cats_final, on='item_category_id', how=\"left\")\n",
    "items = items.drop('item_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test의 shop_id열에서 shop_name이 중복인 값의 shop_id 통일\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11\n",
    "# shops의 shop_id열에서도 shop_name이 중복인 값의 shop_id 통일\n",
    "shops.loc[shops.shop_id == 0, 'shop_id'] = 57\n",
    "shops.loc[shops.shop_id == 0, 'shop_id'] = 57\n",
    "shops.loc[shops.shop_id == 1, 'shop_id'] = 58\n",
    "shops.loc[shops.shop_id == 1, 'shop_id'] = 58\n",
    "shops.loc[shops.shop_id == 10, 'shop_id'] = 11\n",
    "shops.loc[shops.shop_id == 10, 'shop_id'] = 11\n",
    "# shop_name에서 분류가 안되는 값들 분류가 잘 되도록 수정하고, (city나 category명 없거나 띄어쓰기 이상하게 되있거나 한 값들이 꽤 있어서)\n",
    "shops.iloc[0,0] = 'Якутск Орджоникидзе, 56 фран\t'\n",
    "shops.iloc[1,0] = 'Якутск ТЦ \"Центральный\" фран'\n",
    "shops.iloc[6,0] = 'Воронеж  (Плехановская, 13)'\n",
    "shops.iloc[9,0] = ' Выездная Торговля '\n",
    "shops.iloc[10,0] = 'Жуковский  ул.Чкалова39м'\n",
    "shops.iloc[11,0] = 'Жуковский  ул.Чкалова39м²'\n",
    "shops.iloc[12,0] = ' Интернет-магазин ЧС'\n",
    "shops.iloc[20,0] = 'Москва  \"Распродажа\"'\n",
    "shops.iloc[46,0] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops.iloc[55,0] = ' Цифровойсклад1С-Онлайн '\n",
    "shops.iloc[57,0] = 'Якутск  Орджоникидзе'\n",
    "shops['category'] = shops.shop_name.str.split(' ').map(lambda x: x[1])\n",
    "shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n",
    "# shop_id에서 id가 중복되는 행 삭제 (미정)\n",
    "shops.drop_duplicates(['shop_id'],inplace = True)\n",
    "# categoty 항목이 5개 미만이거나 공백인 값들은 other로 변경\n",
    "category = []\n",
    "for cat in shops.category.unique():\n",
    "    if len(shops[shops.category == cat]) >= 5 and cat != '':\n",
    "        category.append(cat)\n",
    "shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )\n",
    "# [\"shop_id\", \"shop_category\", \"shop_city\"] 행만 남게 한 후 라벨 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "shops['shop_category'] = LabelEncoder().fit_transform(shops.category)\n",
    "shops['shop_city'] = LabelEncoder().fit_transform(shops.city)\n",
    "shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier 정리\n",
    "train = train[(train['item_price'] < 100000) & (train['item_price'] > 0)& (train['item_cnt_day'] <1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product = 최대순열 만드는 함수\n",
    "from itertools import product\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "matrix = []\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num == i]\n",
    "    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n",
    "\n",
    "matrix = pd.DataFrame( np.vstack(matrix), columns = [\"date_block_num\", \"shop_id\", \"item_id\"] )\n",
    "matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n",
    "matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n",
    "matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n",
    "matrix.sort_values( [\"date_block_num\", \"shop_id\", \"item_id\"], inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\n",
    "group.columns = [\"item_cnt_month\"]\n",
    "group.reset_index( inplace = True)\n",
    "matrix = pd.merge( matrix, group, on = [\"date_block_num\", \"shop_id\", \"item_id\"], how = \"left\" )\n",
    "matrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"date_block_num\"] = 34\n",
    "test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
    "test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
    "test[\"item_id\"] = test.item_id.astype(np.int16)\n",
    "matrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=[\"date_block_num\", \"shop_id\", \"item_id\"])\n",
    "matrix.fillna( 0, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\n",
    "matrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\")\n",
    "matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\n",
    "matrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\n",
    "matrix[\"type\"] = matrix[\"type\"].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num',\"item_id\"])['item_price'].mean()\n",
    "group.columns = [\"item_price\"]\n",
    "# group.reset_index( inplace = True)\n",
    "matrix = pd.merge(matrix, group, on = ['date_block_num',\"item_id\"], how = \"left\" )\n",
    "matrix[\"item_price\"] = matrix[\"item_price\"].fillna(0).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[\"revenue\"] = matrix[\"item_cnt_month\"] * matrix[\"item_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_list = matrix['item_id'].unique()\n",
    "lis_price = {}\n",
    "for i in item_id_list:\n",
    "    pwd = matrix[matrix['item_id']==i]['item_price']\n",
    "    lis_price[i]=len(pwd.value_counts())\n",
    "item_id_list = matrix['item_id'].unique()\n",
    "item_id_list.sort()\n",
    "item_id_list\n",
    "sample = []\n",
    "for i in item_id_list:\n",
    "    sample.append(lis_price[i])\n",
    "price_merge_sample = pd.DataFrame({'item_id':np.array(item_id_list),'price_unique':np.array(sample)})\n",
    "\n",
    "matrix = pd.merge(matrix, price_merge_sample, on = [\"item_id\"], how = \"left\" )\n",
    "matrix[\"price_unique\"] = matrix[\"price_unique\"].fillna(0).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['Dec_dummy'] = matrix['date_block_num'].apply(lambda x: 1 if x%12==0 else 0)\n",
    "\n",
    "matrix[\"item_category_id\"] = matrix[\"item_category_id\"].fillna(0).astype(np.int16)\n",
    "matrix[\"Dec_dummy\"] = matrix[\"Dec_dummy\"].fillna(0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag 함수 만들기\n",
    "def lag_data( df,lags, cols ):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n",
    "        for i in lags:\n",
    "            shifted = tmp.copy()\n",
    "            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n",
    "            shifted.date_block_num = shifted.date_block_num + i\n",
    "            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = lag_data(matrix, [1,2,3], ['item_cnt_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = lag_data(matrix, [1,2,3], [\"revenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#월평균 아이템 가격의 lag다.\n",
    "matrix = lag_data(matrix, [1,2,3], [\"item_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = lag_data(matrix, [1], [\"Dec_dummy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = matrix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = Y_train.clip(0, 20)\n",
    "Y_valid = Y_valid.clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "params = {'task':['predict'],\n",
    "#           'max_depth':[10,25,50,100]\n",
    "          'boosting_type':['gbdt', 'dart', 'rf'],\n",
    "          'learning_rate':[0.1, 0.5],\n",
    "         'n_estimators':[1000,2000,3000]}\n",
    "#https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "\n",
    "gv_model = GridSearchCV(estimator=lgb_model, param_grid=params)\n",
    "\n",
    "gv_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gv_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    eval_metric=\"rmse\",\n",
    "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
