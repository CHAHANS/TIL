{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드로 이해하는 GAN\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size)\n",
    "    nn.ReLU()\n",
    "    nn.Linear(hidden_size, output_size)\n",
    "    nn.Sigmoid())\n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size)\n",
    "    nn.ReLU()\n",
    "    nn.Linear(hidden_size, image_size)\n",
    "    nn.Tanh())\n",
    "\n",
    "D_loss = torch.mean(torch.log(D(x))) - torch.mean(torch.log(1-D(G(z))))\n",
    "\n",
    "G_loss = torch.mean(torch.log(D(G(z))))\n",
    "```\n",
    "\n",
    "# 활용\n",
    "- [gan-pytorch0.4.0](https://pypi.org/project/gan-pytorch/)\n",
    "- MNIST로 짜여진 가이드 코드를 보면서 공부\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "#Generator model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "\n",
    "def make_generator_model(dataset='mnist'):\n",
    "  \"\"\" implements generate.\n",
    "\n",
    "  Args:\n",
    "    dataset: mnist or cifar10 dataset. (default='mnist'). choice{'mnist', 'cifar'}.\n",
    "\n",
    "  Returns:\n",
    "    model.\n",
    "\n",
    "  \"\"\"\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(layers.Dense(256, input_dim=100))\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(layers.Dense(512))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(layers.Dense(1024))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  if dataset == 'mnist':\n",
    "    model.add(layers.Dense(28 * 28 * 1, activation='tanh'))\n",
    "    model.add(layers.Reshape((28, 28, 1)))\n",
    "  elif dataset == 'cifar':\n",
    "    model.add(layers.Dense(32 * 32 * 3, activation='tanh'))\n",
    "    model.add(layers.Reshape((32, 32, 3)))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "\n",
    "def make_discriminator_model(dataset='mnist'):\n",
    "  \"\"\" implements discriminate.\n",
    "\n",
    "  Args:\n",
    "    dataset: mnist or cifar10 dataset. (default='mnist'). choice{'mnist', 'cifar'}.\n",
    "\n",
    "  Returns:\n",
    "    model.\n",
    "\n",
    "  \"\"\"\n",
    "  model = tf.keras.models.Sequential()\n",
    "  if dataset == 'mnist':\n",
    "    model.add(layers.Flatten(input_shape=[28, 28, 1]))\n",
    "  elif dataset == 'cifar':\n",
    "    model.add(layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "  model.add(layers.Dense(1024))\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(layers.Dense(512))\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(layers.Dense(256))\n",
    "  model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss functions and optimizers for both models.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator loss\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "  \"\"\" This method quantifies how well the discriminator is able to distinguish real images from fakes.\n",
    "      It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions\n",
    "      on fake (generated) images to an array of 0s.\n",
    "\n",
    "  Args:\n",
    "    real_output: origin pic.\n",
    "    fake_output: generate pic.\n",
    "\n",
    "  Returns:\n",
    "    real loss + fake loss\n",
    "\n",
    "  \"\"\"\n",
    "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "  total_loss = real_loss + fake_loss\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator loss\n",
    "def generator_loss(fake_output):\n",
    "  \"\"\" The generator's loss quantifies how well it was able to trick the discriminator.\n",
    "      Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "      Here, we will compare the discriminators decisions on the generated images to an array of 1s.\n",
    "\n",
    "  Args:\n",
    "    fake_output: generate pic.\n",
    "\n",
    "  Returns:\n",
    "    loss\n",
    "\n",
    "  \"\"\"\n",
    "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "def generator_optimizer():\n",
    "  \"\"\" The training generator optimizes the network.\n",
    "\n",
    "  Returns:\n",
    "    optim loss.\n",
    "\n",
    "  \"\"\"\n",
    "  return tf.keras.optimizers.Adam(lr=1e-4)\n",
    "\n",
    "\n",
    "def discriminator_optimizer():\n",
    "  \"\"\" The training discriminator optimizes the network.\n",
    "\n",
    "  Returns:\n",
    "    optim loss.\n",
    "\n",
    "  \"\"\"\n",
    "  return tf.keras.optimizers.Adam(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoints\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def save_checkpoints(generator, discriminator, generator_optimizer, discriminator_optimizer, save_path):\n",
    "  \"\"\" save gan model\n",
    "\n",
    "  Args:\n",
    "    generator: generate model.\n",
    "    discriminator: discriminate model.\n",
    "    generator_optimizer: generate optimizer func.\n",
    "    discriminator_optimizer: discriminator optimizer func.\n",
    "    save_path: save gan model dir path.\n",
    "\n",
    "  Returns:\n",
    "    checkpoint path\n",
    "\n",
    "  \"\"\"\n",
    "  checkpoint_dir = save_path\n",
    "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "  checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                   discriminator_optimizer=discriminator_optimizer,\n",
    "                                   generator=generator,\n",
    "                                   discriminator=discriminator)\n",
    "\n",
    "  return checkpoint_dir, checkpoint, checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the training loop\n",
    "from dataset.load_dataset import load_dataset\n",
    "from network.generator import make_generator_model\n",
    "from network.discriminator import make_discriminator_model\n",
    "from util.loss_and_optim import generator_loss, generator_optimizer\n",
    "from util.loss_and_optim import discriminator_loss, discriminator_optimizer\n",
    "from util.save_checkpoints import save_checkpoints\n",
    "from util.generate_and_save_images import generate_and_save_images\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='mnist', type=str,\n",
    "                    help='use dataset {mnist or cifar}.')\n",
    "parser.add_argument('--epochs', default=50, type=int,\n",
    "                    help='Epochs for training.')\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "# define model save path\n",
    "save_path = 'training_checkpoint'\n",
    "\n",
    "# create dir\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "\n",
    "# define random noise\n",
    "noise = tf.random.normal([16, 100])\n",
    "\n",
    "# load dataset\n",
    "mnist_train_dataset, cifar_train_dataset = load_dataset(60000, 128, 50000, 64)\n",
    "\n",
    "# load network and optim paras\n",
    "generator = make_generator_model(args.dataset)\n",
    "generator_optimizer = generator_optimizer()\n",
    "\n",
    "discriminator = make_discriminator_model(args.dataset)\n",
    "discriminator_optimizer = discriminator_optimizer()\n",
    "\n",
    "checkpoint_dir, checkpoint, checkpoint_prefix = save_checkpoints(generator,\n",
    "                                                                 discriminator,\n",
    "                                                                 generator_optimizer,\n",
    "                                                                 discriminator_optimizer,\n",
    "                                                                 save_path)\n",
    "\n",
    "\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  \"\"\" break it down into training steps.\n",
    "\n",
    "  Args:\n",
    "    images: input images.\n",
    "\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(noise, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss,\n",
    "                                             generator.trainable_variables)\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss,\n",
    "                                                  discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(\n",
    "    zip(gradients_of_generator, generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(\n",
    "    zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "def train(dataset, epochs):\n",
    "  \"\"\" train op\n",
    "\n",
    "  Args:\n",
    "    dataset: mnist dataset or cifar10 dataset.\n",
    "    epochs: number of iterative training.\n",
    "\n",
    "  \"\"\"\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             noise,\n",
    "                             save_path)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print(f'Time for epoch {epoch+1} is {time.time()-start:.3f} sec.')\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           noise,\n",
    "                           save_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  if args.dataset == 'mnist':\n",
    "    train(mnist_train_dataset, args.epochs)\n",
    "  else:\n",
    "    train(cifar_train_dataset, args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate and save images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Chat으로 만든경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN이미지 생성하는 chat.gpt 답변\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_dim=784):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.img_dim = img_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=784):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_dim = img_dim\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.dis(x)\n",
    "\n",
    "# Training Function\n",
    "def train_gan(generator, discriminator, dataloader, optimizer_G, optimizer_D, criterion, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(batch_size, -1).to(device)\n",
    "            z = torch.randn(batch_size, generator.z_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            real_preds = discriminator(real_images)\n",
    "            real_loss = criterion(real_preds, torch.ones_like(real_preds))\n",
    "            fake_preds = discriminator(fake_images)\n",
    "            fake_loss = criterion(fake_preds, torch.zeros_like(fake_preds))\n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, generator.z_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            fake_preds = discriminator(fake_images)\n",
    "            g_loss = criterion(fake_preds, torch.ones_like(fake_preds))\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Print Losses\n",
    "            if i == len(dataloader)-1:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}')\n",
    "                \n",
    "                # Save Generated Images\n",
    "                os.makedirs('gan_images', exist_ok=True)\n",
    "                save_image(fake_images.view(fake_images.size(0), 1, 28, 28), f'gan_images/{epoch+1}.png', normalize=True)\n",
    "                \n",
    "# Hyperparameters\n",
    "z_dim = 100\n",
    "img_dim = 28*28\n",
    "lr = 0.0002\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/c/Users/User/Desktop/Lab/TIL/MLDLstudy/GAN/testimg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# 데이터셋 준비\u001b[39;00m\n\u001b[0;32m     18\u001b[0m transform \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m     19\u001b[0m     torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mResize(image_size),\n\u001b[0;32m     20\u001b[0m     torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m     21\u001b[0m     torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m), (\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m)),\n\u001b[0;32m     22\u001b[0m ])\n\u001b[1;32m---> 23\u001b[0m dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mImageFolder(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/c/Users/User/Desktop/Lab/TIL/MLDLstudy/GAN/testimg\u001b[39;49m\u001b[39m'\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[0;32m     24\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[39m# 모델 초기화\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torchvision\\datasets\\folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m ):\n\u001b[1;32m--> 310\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    311\u001b[0m         root,\n\u001b[0;32m    312\u001b[0m         loader,\n\u001b[0;32m    313\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    315\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    316\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    317\u001b[0m     )\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    137\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    146\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torchvision\\datasets\\folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    193\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '/c/Users/User/Desktop/Lab/TIL/MLDLstudy/GAN/testimg'"
     ]
    }
   ],
   "source": [
    "#학습을 위한 코드\n",
    "# 필요한 패키지 import\n",
    "import torch\n",
    "import torchvision\n",
    "# from gan import Generator, Discriminator, train_gan\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "image_size = 64\n",
    "noise_size = 100\n",
    "\n",
    "# GPU 사용 여부\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터셋 준비\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(image_size),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "dataset = torchvision.datasets.ImageFolder(root='data_path', transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 모델 초기화\n",
    "generator = Generator(noise_size, image_size).to(device)\n",
    "discriminator = Discriminator(image_size).to(device)\n",
    "\n",
    "# 손실 함수 및 최적화 알고리즘 정의\n",
    "criterion = torch.nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# GAN 모델 학습\n",
    "train_gan(generator, discriminator, dataloader, criterion, g_optimizer, d_optimizer, num_epochs, noise_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/User/Desktop/Lab/TIL/MLDLstudy/GAN\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ceb170a46183f1a7e0663fa1bfaf6582e83c617295d9a5086de71a269a23da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
